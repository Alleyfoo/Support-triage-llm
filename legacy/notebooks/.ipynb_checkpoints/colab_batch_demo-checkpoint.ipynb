{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Batch demo with Colab\n",
        "This notebook shows how to run the customer-service pipeline on ten sample emails inside Google Colab, display the replies, and export the batch to Excel. The steps assume the notebook lives in the `notebooks/` directory of the project (as when opened via GitHub \u2192 \"Open in Colab\").\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install dependencies\n",
        "Install the project requirements into the Colab runtime. When the notebook is opened from the repo, the parent folder contains `requirements.txt`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd ../\n",
        "%pip install -q -r requirements.txt\n",
        "%cd notebooks/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure the runtime\n",
        "Set the backend to the deterministic stub (so the notebook does not require Ollama/llama.cpp) and load helper modules.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from app.pipeline import run_pipeline\n",
        "\n",
        "os.environ.setdefault('MODEL_BACKEND', 'stub')\n",
        "os.environ.setdefault('PIPELINE_LOG_PATH', '')\n",
        "\n",
        "data_path = Path('../data/test_emails.json')\n",
        "records = json.loads(data_path.read_text())\n",
        "df = pd.DataFrame(records)\n",
        "df['expected_keys'] = df['expected_keys'].apply(lambda v: v or [])\n",
        "df = df.rename(columns={'body': 'email'})\n",
        "batch_df = df.head(10).copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Review sample emails\n",
        "Preview the first ten emails and their expected keys before invoking the model to establish ground truth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "preview"
      },
      "outputs": [],
      "source": [
        "preview_df = batch_df[['id', 'subject', 'email', 'expected_keys']].copy()\n",
        "preview_df['expected_keys'] = preview_df['expected_keys'].apply(lambda keys: ', '.join(keys))\n",
        "preview_df.reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Run the pipeline and append results\n",
        "Loop over the batch DataFrame, call `run_pipeline`, and enrich it with replies, answers, and evaluation scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run"
      },
      "outputs": [],
      "source": [
        "rows = []\n",
        "for _, row in batch_df.iterrows():\n",
        "    metadata = {'expected_keys': row.get('expected_keys')}\n",
        "    result = run_pipeline(row['email'], metadata=metadata)\n",
        "    rows.append({\n",
        "        'id': row['id'],\n",
        "        'subject': row['subject'],\n",
        "        'email': row['email'],\n",
        "        'expected_keys': ', '.join(row.get('expected_keys', [])),\n",
        "        'reply': result.get('reply', ''),\n",
        "        'answers': json.dumps(result.get('answers', {}), ensure_ascii=False),\n",
        "        'score': result.get('evaluation', {}).get('score'),\n",
        "        'matched': ', '.join(result.get('evaluation', {}).get('matched', [])),\n",
        "        'missing': ', '.join(result.get('evaluation', {}).get('missing', [])),\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(rows)\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Save to Excel\n",
        "Write the enriched DataFrame to an Excel workbook so the responses can be shared or audited.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save"
      },
      "outputs": [],
      "source": [
        "output_path = Path('colab_batch_responses.xlsx')\n",
        "results_df.to_excel(output_path, index=False)\n",
        "output_path.resolve()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Download from Colab (optional)\n",
        "If you're in Colab, run the next cell to download the Excel file to your local machine.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(str(output_path))\n",
        "except ImportError:\n",
        "    print('google.colab is unavailable outside Colab; skip download step.')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab_batch_demo.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}