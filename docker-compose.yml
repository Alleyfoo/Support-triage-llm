version: "3.9"

services:
  # The Brain (Ollama)
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama-models:/root/.ollama
    # Uncomment for GPU
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    networks:
      - internal

  # The Body (Daemon)
  bot:
    build: .
    command: python tools/daemon.py
    env_file:
      - .env
    environment:
      - DB_PATH=/data/queue.db
      - OLLAMA_HOST=http://ollama:11434
      # Ensure these are set in .env for daemon ingest/sent sync:
      # IMAP_HOST, IMAP_USERNAME, IMAP_PASSWORD
    volumes:
      - ./data:/app/data
      - ./docs:/app/docs
    depends_on:
      - ollama
    restart: unless-stopped
    networks:
      - internal

  # Optional dashboard (analytics/history)
  dashboard:
    build: .
    command: streamlit run ui/monitor.py --server.port=8501
    environment:
      - DB_PATH=/data/queue.db
    volumes:
      - ./data:/app/data
    ports:
      - "8501:8501"
    networks:
      - internal

networks:
  internal:
    driver: bridge

volumes:
  ollama-models:
